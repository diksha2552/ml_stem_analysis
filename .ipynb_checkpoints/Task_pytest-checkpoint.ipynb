{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "import pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variable\n",
    "file_path = \"<file_path>/word_cloud/2010 Federal STEM Education Inventory Data Set.xls\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_path):\n",
    "    # Read the input data file\n",
    "    df = pd.read_excel(file_path , header = 1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_growth_category(df):\n",
    "    # Calculate the growth parameter based on funding growth\n",
    "    df['Growth'] = (df['C2) Funding FY2009'] - df['C1) Funding FY2008'])/df['C1) Funding FY2008'] * 100\n",
    "    \n",
    "    # Assign categorical binary label based on growth \n",
    "    Tag =[]\n",
    "    val = float()\n",
    "    for val in df.Growth:\n",
    "        Tag.append('0') if val < 0 else Tag.append('1')\n",
    "    df['Target_var'] = pd.Series(Tag)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Test cases:\n",
    "# Test for presence of only set([0,1]) in set(df['Target_var'])\n",
    "def test_calculate_growth_category():\n",
    "    df = read_file(file_path)\n",
    "    df = calculate_growth_category(df)\n",
    "    set1 = {'0','1'}\n",
    "    set2 = pd.Series(df['Target_var'])\n",
    "    set3 = set(set2)\n",
    "    assert set1 == set3\n",
    "    \n",
    "    \n",
    "def form_training_data(df):\n",
    "    df = calculate_growth_category(df)\n",
    "    # Concatenating text data to form the training data\n",
    "    df.fillna('', inplace=True)\n",
    "    df['concatented_data'] = df[['Investment Name', 'Agency', 'Subagency', 'A) Brief Description']].apply(lambda x: ''.join(x), axis=1)\n",
    "    \n",
    "    # data as concatenated text in the sheet, labels as Target_var\n",
    "    X = list(df['concatented_data'])\n",
    "    y = list(df['Target_var'])\n",
    "    y = [int(val) for val in y]\n",
    "    return df, X, y\n",
    "\n",
    "\n",
    "# Test cases:\n",
    "# Test for X input has certain string \n",
    "def test_form_training_data():\n",
    "    df = read_file(file_path)\n",
    "    df,X,y = form_training_data(df)\n",
    "    assert df[\"concatented_data\"].str.contains(\"Polar Research and EducationNational Science FoundationOffice of Polar Programs\").any() == True\n",
    "\n",
    "\n",
    "# Test for y has only (0, 1)\n",
    "def test_form_training_data_two(): \n",
    "    df = read_file(file_path)\n",
    "    df,X,y = form_training_data(df)\n",
    "    set1 = set(y)\n",
    "    set2 = {0,1}\n",
    "    assert set1 == set2\n",
    "    \n",
    "'''\n",
    "TfidfVectorizer - Term Frequency (Tf)-Inverse Document Frequency (idf)\n",
    "Transforms text to feature vectors that can be used as input to estimator\n",
    "'''\n",
    "def feature_extraction(X): \n",
    "    # Finding TFIDF Features for the text data\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    vectoriser_model = vectorizer.fit(X)\n",
    "    X = vectorizer.transform(X)\n",
    "    return vectoriser_model, X\n",
    "\n",
    "\n",
    "# Test cases:\n",
    "# Count the length of X_train, y_train to be test_size of total length\n",
    "# Count the lenght of X_test, y_test to be test_size of total length \n",
    "def split_data(X, y, test_size=0.3):\n",
    "    # Spliting data into train and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, stratify=y)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "# Test cases:\n",
    "# Count the length of X_train, X_test to be test_size of total length\n",
    "def test_split_data(): \n",
    "    df = read_file(file_path)\n",
    "    df, X, y = form_training_data(df)\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y, test_size=0.3)\n",
    "    assert len(X) == (len(X_train) + len(X_test))\n",
    "    \n",
    "    \n",
    "# Count the lenght of y_train, y_test to be test_size of total length\n",
    "def test_split_data_two(): \n",
    "    df = read_file(file_path)\n",
    "    df, X, y = form_training_data(df)\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y, test_size=0.3)\n",
    "    assert len(y) == (len(y_train) + len(y_test))\n",
    "    \n",
    "    \n",
    "def train_model(X_train, y_train):\n",
    "    # fit model on training data\n",
    "    model = XGBClassifier()\n",
    "    trained_model = model.fit(X_train, y_train)\n",
    "    return trained_model\n",
    "\n",
    "\n",
    "def predict(model, X_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "# Test case:\n",
    "# Test len(y_test) == len(y_pred)\n",
    "def test_predict():\n",
    "    df = read_file(file_path)\n",
    "    model = XGBClassifier()\n",
    "    trained_model = model.fit(X_train, y_train)\n",
    "    y_pred = predict(model, X_test)\n",
    "    assert (len(y_test) == len(y_pred))\n",
    "    \n",
    "    \n",
    "def evaluate(y_test, y_pred):\n",
    "    # evaluate predictions\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f_score = f1_score(y_test, y_pred)\n",
    "    print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "    print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
    "    print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
    "    print(\"F1_score: %.2f%%\" % (f_score * 100.0))\n",
    "    \n",
    "    \n",
    "# Test cases:\n",
    "# Test that positive_label should belong to set(y_test)\n",
    "# Test len(y_test) == len(y_pred)\n",
    "def visualisation(y_test, y_pred, positive_label=1):\n",
    "    # ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label=positive_label)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file and insert growth and target variable\n",
    "df = read_file(file_path)\n",
    "df = calculate_growth_category(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form training and testing dataset\n",
    "df, X, y = form_training_data(df)\n",
    "vectoriser_model, X = feature_extraction(X)\n",
    "X_train, X_test, y_train, y_test = split_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model and get prediciton on the testing data\n",
    "XGB_model = train_model(X_train, y_train)\n",
    "y_pred = predict(XGB_model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate and visualise\n",
    "evaluate(y_test, y_pred)\n",
    "visualisation(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
